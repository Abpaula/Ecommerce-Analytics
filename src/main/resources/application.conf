loganalysis {
  spark {
    master = "local"
    name = "Ecommerce Log Analysis"
    batch.interval = "5000"
    window.interval = "30000"
    max.rate.per.partition = "500"
    ip.lookup.file = "src/main/resources/all_classbs.txt"
  }

  kafka {
    bootstrap.server = "localhost:9092"
    topic = "ecommerceLogs"
    group.id = "EcommerceLogProcessing"
    key.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
    //value.deserializer = "io.confluent.kafka.serializers.KafkaAvroDeserializer"
    value.deserializer = "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    schema.registry = "http://localhost:8081"
  }

  cassandra {
      hostname = "localhost"
      keyspace = "logeventskeyspace"
      table.page.views = "page_views"
      table.status.counter = "status_counter"
      table.visit.by.country = "visits_by_country"
      table.referrer.counter = "referrer_counter"

      output.batch.size.bytes = "5120"
  }

  zookeeper {
    quorum = "localhost:2181"
    port = 2181
    znode.parent = "/ecommerceLoganalysis"
  }
}